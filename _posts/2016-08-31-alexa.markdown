---
layout:     post
title:      "Amazon alexa and AVS"
subtitle:   "智能语音系统alexa移植到linux平台音箱"
date:       2016-08-31
author:     "luobu"
header-img: "img/post/alexa/alexa.jpg"
catalog:    true
tags:
    - alexa
    - 语音识别
    - AVS
---


Amazon 的智能音箱 Echo 在北美以及欧洲市场大卖，广受用户好评。其搭载的智能助手 alexa ，作为其核心的智能语音识别系统，也受到了大家的广泛关注。  
好在亚马逊开放了 alexa 的相关接口，Alexa Voice Service（AVS）的开放，使得广大的极客、爱好者、中小型音箱/智能家居企业，都有机会将 Amazon 先进的语音识别系统应用于自己的产品之中。尽管 alexa 的某些功能，如播放音乐、购物等等在国内可能没法实现，而且我们自己通过简单的硬件平台，如 Raspberry Pi 等环境实现的 demo 效果和 Echo 想比还有不小的差距（关键词唤醒、语音识别的准确率、距离、音频返回的速度等等），不过这些依然不能影响我们对他基本功能的体验（记得对他说英语）。


### Alexa Voice Service

Amazon 官方对 [AVS](https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/getting-started-with-the-alexa-voice-service) 的介绍：  

> The Alexa Voice Service (AVS) allows you to integrate Alexa’s built-in voice capabilities into your connected products. With AVS, your users will have the ability to play music, request the weather forecast and local news, get updates on traffic conditions, ask general knowledge questions, set timers and alarms, query Wikipedia and much more, the same way they would with an Amazon Echo. You also have access to third-party skills developed using the Alexa Skills Kit (ASK). Using AVS and ASK together, you can build sophisticated interactions to extend the capabilities of your Alexa-enabled product.

### AVS with cURL
在 linux 上如果使用 c 语言（主要考虑到一些跑不了高级语言的嵌入式 Linux 平台）来实现 AVS 的通讯接口的话，因为要涉及到 http 协议的数据传输，当然最新的 AVS 还需要 http2.0 的支持（2015年刚出的这个协议，有坑，这里有一些语言对 http2 的[实现](https://github.com/http2/http2-spec/wiki/Implementations)，为了使 libcurl 支持 http2，我们需要先安装 [nghttp2](https://nghttp2.org)），使用 cURL 来实现无疑是效率最高的选择。具体步骤如下（节选自一位外国小哥的 blog）：

#### Generate sample audio
The audio MUST be ***mono channel***, sampled at ***16k Hz***, and ***signed 16 bit PCM*** encoding. Otherwise AVS will send back a blank response. There is a fantastic command line tool available called [**SoX**](http://sox.sourceforge.net/sox.html) for recording as well as converting audio to specified formats. We can record audio right from our terminal like in this example:  

``` bash
$ sox -d -c 1 -r 16000 -e signed -b 16 hello.wav

Input File     : 'default' (coreaudio)
Channels       : 2
Sample Rate    : 44100
Precision      : 32-bit
Sample Encoding: 32-bit Signed Integer PCM
In:0.00% 00:00:01.72 [00:00:00.00] Out:25.8k [      |      ]        Clip:0
```
Alternatively, we can use the `rec` command instead of `sox -d`.  
SoX comes with a `play` command for doing exactly what it says. Here an example where we pipe the audio contents:  

``` bash
$ cat hello.wav | play -
-: (wav)

  Encoding: Signed PCM
  Channels: 1 @ 16-bit
  Samplerate: 16000Hz
  Replaygain: off
  Duration: 00:00:01.44

In:100%  00:00:01.44 [00:00:00.00] Out:63.3k [   -==|==-   ] Hd:0.0 Clip:1
play WARN rate: rate clipped 1 samples; decrease volume?
Done.
```
We can see that the audio sample rate and encoding are exactly what we need. And we can use SoX to change the sample rate, encoding, and number of channels. Here is an example where we transform the audio into the format required by AVS:

``` bash
$ cat hello_stero.wav | sox - -c 1 -r 16000 -e signed -b 16 hello.wav
```
The `-` means to use standard input (stdin) as the audio source.

#### Creating cURL request
The [AVS Speechrecognizer Requests API](https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/speechrecognizer) page shows an example of what kind of request we should send. As you can see it is a multipart request with one of the parts being the binary audio data.  

``` bash
POST /v1/avs/speechrecognizer/xxxxxxxxxxxx HTTP/1.1

Host: access-alexa-na.amazon.com
Authorization: Bearer xxxxxxxxxxxx
Content-Type: multipart/form-data; boundary=boundary_term
Transfer-Encoding: chunked

--boundary_term
Content-Disposition: form-data; name="request"
Content-Type: application/json; charset=UTF-8

{
    "messageHeader": {
        "deviceContext": [
            {
                "name": "playbackState",
                "namespace": "AudioPlayer"
                "payload": {
                    "streamId": "xxxxxxxxxxxx",
                    "offsetInMilliseconds": xxxxxxxxxxxx,
                    "playerActivity": "xxxxxxxxxxxx"
                }
            },
            {
                ...
            },
            ...
        ]
    },
    "messageBody": {
        "profile": "alexa-close-talk",
        "locale": "en-us",
        "format": "audio/L16; rate=16000; channels=1"
    }
}

--boundary_term
Content-Disposition: form-data; name="audio"
Content-Type: audio/L16; rate=16000; channels=1

...encoded_audio_data...

--boundary_term--
```

原博客使用的是 http1.0 的协议，我们跟随科技发展的趋势看一下 http2.0 的：
![img](/img/post/alexa/h2.png)
**Request**

``` bash
// Note: HTTP2 is a binary protocol and the payload is not human-readable. This is for illustrative purposes only.

:method = POST
:scheme = https
:path = /v20160207/events
authorization = Bearer foo-bar
content-type = multipart/form-data; boundary=this-is-a-boundary

--this-is-a-boundary
Content-Disposition: form-data; name="metadata"
Content-Type: application/json; charset=UTF-8

{
    "context": [
        {
            "header": {
                "namespace": "AudioPlayer",
                "name": "PlaybackState"
            },
            "payload": {
                "token": "abcd1234",
                "offsetInMilliseconds": 7000,
                "playerActivity": "PLAYING"
            }
        },
        {
            "header": {
                "namespace": "Alerts",
                "name": "AlertsState"
            },
            "payload": {
                "allAlerts": [
                    {
                        "token": "foo-bar",
                        "type": "ALARM",
                        "scheduledTime": "2015-10-30T22:34:51+00:00"
                    }
                ],
                "activeAlerts": [
                ]
            }
        },
        {
            "header": {
                "namespace": "Speaker",
                "name": "VolumeState"
            },
            "payload": {
                "volume": 25,
                "muted": false
            }
        },
        {
            "header": {
                "namespace": "SpeechSynthesizer",
                "name": "SpeechState"
            },
            "payload": {
                "token": "zxcv8523",
                "offsetInMilliseconds": 0,
                "playerActivity": "FINISHED"
            }
        }
    ],
    "event": {
        "header": {
            "namespace": "SpeechRecognizer",
            "name": "Recognize",
            "messageId": "messageId-123",
            "dialogRequestId": "dialogRequestId-321"
        },
        "payload": {
            "profile": "CLOSE_TALK",
            "format": "AUDIO_L16_RATE_16000_CHANNELS_1"
        }
    }
}

--this-is-a-boundary
Content-Disposition: form-data; name="audio"
Content-Type: application/octet-stream

{{binary audio attachment}}
--this-is-a-boundary--
```  
**Response**

``` bash
:status = 200
content-type = multipart/related; boundary=this-is-a-boundary; type="application/json"

--this-is-a-boundary
Content-Type: application/json; charset=UTF-8

{
    "directive": {
        "header": {
            "namespace": "SpeechSynthesizer",
            "name": "Speak",
            "messageId": "ewq-321",
            "dialogRequestId": "dialogRequestId-321"
        },
        "payload": {
            "url": "cid:1234",
            "format": "AUDIO_MPEG"
            "token": "kr17447380422"
        }
    }
}

--this-is-a-boundary
Content-Type: application/octet-stream
Content-ID: <1234>

{{binary audio attachment}}
--this-is-a-boundary--
```
Here I have created this is a basic bash script that composes the cURL command. I walk us through the steps in the comments to clarify what is going on. Also if you have not already, you will need an authentication token which you can get by following this [Authorizing Your Alexa-enabled Product from a Website](https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/docs/authorizing-your-alexa-enabled-product-from-a-website) guide.

``` bash
############################################################
# First we creat a bunch of variables to hold data.
############################################################

# Auth token (replace with yours).
TOKEN="Atza|IQEBLjAsAhR..."

# Boundary name, must be unique so it does not conflict with any data.
BOUNDARY="BOUNDARY1234"
BOUNDARY_DASHES="--"

# Newline characters.
NEWLINE='\r\n';

# Metadata headers.
METADATA_CONTENT_DISPOSITION="Content-Disposition: form-data; name=\"metadata\"";
METADATA_CONTENT_TYPE="Content-Type: application/json; charset=UTF-8";

# Metadata JSON body.
METADATA="{\
\"messageHeader\": {},\
\"messageBody\": {\
\"profile\": \"alexa-close-talk\",\
\"locale\": \"en-us\",\
\"format\": \"audio/L16; rate=16000; channels=1\"\
}\
}"

# Audio headers.
AUDIO_CONTENT_TYPE="Content-Type: audio/L16; rate=16000; channels=1";
AUDIO_CONTENT_DISPOSITION="Content-Disposition: form-data; name=\"audio\"";

# Audio filename (replace with yours).
AUDIO_FILENAME="hello.wav"

############################################################
# Then we start composing the body using the variables.
############################################################

# Compose the start of the request body, which contains the metadata headers and
# metadata JSON body as the first part of the multipart body.
# Then it starts of the second part with the audio headers. The binary audio
# will come later as you will see.
POST_DATA_START="
${BOUNDARY_DASHES}${BOUNDARY}${NEWLINE}${METADATA_CONTENT_DISPOSITION}${NEWLINE}\
${METADATA_CONTENT_TYPE}\
${NEWLINE}${NEWLINE}${METADATA}${NEWLINE}${NEWLINE}${BOUNDARY_DASHES}${BOUNDARY}${NEWLINE}\
${AUDIO_CONTENT_DISPOSITION}${NEWLINE}${AUDIO_CONTENT_TYPE}${NEWLINE}"

# Compose the end of the request body, basically just adding the end boundary.
POST_DATA_END="${NEWLINE}${NEWLINE}${BOUNDARY_DASHES}${BOUNDARY}${BOUNDARY_DASHES}${NEWLINE}"

############################################################
# Now we create a request body file to hold everything including the binary audio data.
############################################################

# Write metadata to a file which will contain the multipart request body content.
echo -e $POST_DATA_START > multipart_body.txt

# Here we append the binary audio data to request body file
# by spitting out the contents. We do it this way so that
# the encoding do not get messed with.
cat $AUDIO_FILENAME >> multipart_body.txt

# Then we append closing boundary to request body file.
echo -e $POST_DATA_END >> multipart_body.txt

############################################################
# Finally we get to compose the cURL request command
# passing it the generated request body file as the multipart body.
############################################################

# Compose cURL command and write to output file.
curl -X POST \
  -H "Authorization: Bearer ${TOKEN}" \
  -H "Content-Type: multipart/form-data; boundary=${BOUNDARY}" \
  --data-binary @multipart_body.txt \
  https://access-alexa-na.amazon.com/v1/avs/speechrecognizer/recognize \
  > response.txt
```
Save the contents to request.sh, make it executable, and run it. If all went well we should get a response similar to this one:

``` bash
--a7ed2d26-a20f-474a-b4be-a589e1130d1e
Content-Type: application/json

{"messageHeader":{},"messageBody":{"directives":[{"namespace":"SpeechSynthesizer","name":"speak","payload":{"contentIdentifier":"amzn1.as-ct.v1.Domain:Application:Knowledge#ACRI#KnowledgePrompt.ab324d01-e5de-4945-8606-a1f03fdc7df0","audioContent":"cid:KnowledgePrompt.ab324d01-e5de-4945-8606-a1f03fdc7df0_1560908845"}}]}}
--a7ed2d26-a20f-474a-b4be-a589e1130d1e
Content-ID: <KnowledgePrompt.ab324d01-e5de-4945-8606-a1f03fdc7df0_1560908845>
Content-Type: audio/mpeg

...encoded_audio_data...
--a7ed2d26-a20f-474a-b4be-a589e1130d1e--
```

#### Playing audio

The tool [mpg123](http://www.mpg123.de) lets you play MP3 audio from the terminal. In order to extract the MP3 audio data from the response we need to use an HTTP message parser. Here is one that I wrote, [http-message-parser](https://github.com/miguelmota/http-message-parser), which lets you pipe the response and pipe out the parts that we want.

Pipe MP3 data to mpg123 player:

``` bash
$ cat response.txt | http-message-parser --pick=multipart[1].body | mpg123 -

High Performance MPEG 1.0/2.0/2.5 Audio Player for Layers 1, 2 and 3
        version 1.22.4; written and copyright by Michael Hipp and others
        free software (LGPL) without any warranty but with best wishes

Playing MPEG stream 1 of 1: - ...

MPEG 2.0 layer III, 48 kbit/s, 24000 Hz mono

[0:02] Decoding of - finished.
```

到这里，整个工作就算完成了，当然还有很多可以优化的地方。比如：post 的数据可以简化（下面一章就是简化版本），另外 get 回来的 response 数据包含二进制音频文件，所以直接去除 http 的头和尾然后重命名为 wav 文件即可，这样效率最高（转化成 .mp3 格式并非必须，只要播放器支持就可以）。

### Easier way to request

I recently stumbled across a much cleaner way of initiating the request. Here it is:  

**metadata.json**

``` json
{
  "messageHeader": {},
  "messageBody": {
    "profile": "alexa-close-talk",
    "locale": "en-us",
    "format": "audio/L16; rate=16000; channels=1"
  }
}
```
**request.sh**

``` bash
TOKEN="Atza|IQEBLjAsAhR..."

curl -i \
  -H "Authorization: Bearer ${TOKEN}" \
  -F "metadata=<metadata.json;type=application/json; charset=UTF-8" \
  -F "audio=<hello.wav;type=audio/L16; rate=16000; channels=1" \
  -o response.txt \
  https://access-alexa-na.amazon.com/v1/avs/speechrecognizer/recognize \
```
The `-i` flag means to output the response headers. The `-H` flag specifies headers. The `-F` flag causes cURL to send a POST `multipart/form-data` request and `<` indicates that we want the contents of the file to sent instead of the actual file. Finally, `-o` specifies the output file.